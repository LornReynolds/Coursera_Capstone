{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Coursera Capstone Project", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "- This Jupyter Notebook will be used primarily for the requirements set forth in the final Capstone project", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "import pandas as pd\nimport numpy as np"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "print(\"Hello Capstone Project Course!\")"
        }, 
        {
            "source": "# Continuing to build upon the previous notebook submission\n### Utilizing BeautifulSoup, urllib and read_html to scrape data from the source Wikipedia page into a Pandas Dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "from bs4 import BeautifulSoup"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "import urllib\nurl = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\nurllib.request.urlopen(url)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "dfs = pd.read_html(url)\ndf = dfs[0]\ndf.head(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "type(df)"
        }, 
        {
            "source": "## The starting dimensions of the table are 289 rows and 3 columns", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df.shape"
        }, 
        {
            "source": "## This step will rename the columns to the column headers scraped from the website", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df1 = df.rename(columns=df.iloc[0])\ndf1.head(10)"
        }, 
        {
            "source": "## The following step identifies which of the Borough values equal \"Not assigned\" and drops those rows from the table, resulting in the removal of 77 rows", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Get names of indexes for which column Borough has value 'Not assigned'\nindexNames = df1[df1['Borough'] == 'Not assigned'].index\n \n# Delete these row indexes from dataFrame\ndf1.drop(indexNames, inplace=True)\n\ndf1.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df1.head(10)"
        }, 
        {
            "source": "## The following step is performed to clean up the table appearance by removing the first row containing values equal to the column headers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df2 = df1.drop(df1.index[0])\ndf2.head(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df2.shape"
        }, 
        {
            "source": "## Assigning the Borough value to the Neighbourhood column with values of \"Not assigned\" (see row index 9)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df2.loc[df2['Neighbourhood'] == 'Not assigned', 'Neighbourhood'] = df2['Borough']\ndf2.head(15)"
        }, 
        {
            "source": "## Identifying and grouping rows with identical Postcode values and Borough values.  At the same time, combining the Neighbourhood values into a single row using a join function and resetting the index, but ensuring the groupby does not conduct the default sort based on the Postcode.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df3 = df2.groupby(['Postcode','Borough'],sort=False)['Neighbourhood'].apply(lambda x: ', '.join(x.astype(str))).reset_index()\ndf3.head(15)"
        }, 
        {
            "source": "## Outputting the final dimensions of the dataframe; the previous step removed a significant number of rows resulting in a final count of 103 rows and 3 columns.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df3.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "import numpy as np \nimport pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport json\n\n! conda install -c conda-forge geopy --yes\nfrom geopy.geocoders import Nominatim\n\nimport requests\nfrom pandas.io.json import json_normalize\n\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering\n\nprint('All have been imported and you are ready to proceed!')"
        }, 
        {
            "source": "#### Contingency Data\nhttps://cocl.us/Geospatial_data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df3.columns"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df4 = pd.read_csv(\"https://cocl.us/Geospatial_data\")\ndf4.columns"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df4.rename(columns={'Postal Code': 'Postcode'}, inplace=True)\ndf4.columns"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df5 = pd.merge(df3, df4, on='Postcode', how='outer')\ndf5.groupby('Postcode', sort=False)\ndf5"
        }, 
        {
            "source": "### Use the geopy library to get the latitude and longitude values of Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "address = 'Toronto, Canada'\n\ngeolocator = Nominatim(user_agent='toronto_explorer')\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geographical coordinates of Toronto Canada are {}, {}.'.format(latitude, longitude))"
        }, 
        {
            "source": "### Create a map of Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# Create a map of Toronto\n#latitude=43.70011\n#longitude=-79.4163\nmap_Toronto = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# add markers to the map\nfor lat, lng, borough, neighbourhood in zip(df5['Latitude'], df5['Longitude'], df5['Borough'], df5['Neighbourhood']):\n    label = ('{}'.format(borough + ' , ' + neighbourhood))\n    label = folium.Popup(str(label), parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=7,\n        parse_html=False).add_to(map_Toronto)\n\nmap_Toronto"
        }, 
        {
            "source": "print(df5[df5['Borough'].str.contains(\"Toronto\")])\n\nThis cell can be changed from Markdown in order to identify Buroughs with \"Toronto\" in the name", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_data = df5"
        }, 
        {
            "source": "toronto_data = df5[df5['Borough'].str.contains(\"Toronto\")].reset_index(drop=True)\ntoronto_data\n\nThis cell can be changed from Markdown to limit the data set to Boroughs that contain \"Toronto\" in the name", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Sensitive Cell\nCLIENT_ID ='MKPDVLWEHMEB3INFYKHU5RY5OQH2G4DIM5GHWRL0D4Y004OS'\nCLIENT_SECRET = 'DUKSMGJ4ES5M1YDDZIFUJS0YR0HX1ZGQXJ12JW4VQS1GCAVB'\nVERSION = '20180605'"
        }, 
        {
            "source": "### Taking the first entry in our dataframe, we can explore nearby venues\n#### (Extract the name, latitude, longitude, etc.)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_data.loc[0, 'Neighbourhood']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "neighbourhood_lat = toronto_data.loc[0, 'Latitude'] # latitude of the neighbourhood\nneighbourhood_lng = toronto_data.loc[0, 'Longitude'] # longitude of the neighbourhood\nneighbourhood_name = toronto_data.loc[0, 'Neighbourhood'] # name of the neighbourhood\n\nprint('Latitude and longitude of {} are {}, {}'.format(neighbourhood_name, \n                                                neighbourhood_lat, \n                                                neighbourhood_lng))"
        }, 
        {
            "source": "#### The top 100 venues within a 500 meter radius of Parkwoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "LIMIT = 100\nradius = 500\n\nurl2 = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID,\n    CLIENT_SECRET,\n    VERSION,\n    neighbourhood_lat,\n    neighbourhood_lng,\n    radius,\n    LIMIT)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "results = requests.get(url2).json()\nresults"
        }, 
        {
            "source": "### Extract the category of the venue", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "def get_category_type(row):\n        try:\n            categories_list = row['categories']\n        except:\n            categories_list = row['venue.categories']\n            \n        if len(categories_list) == 0:\n            return None\n        else:\n            return categories_list[0]['name']"
        }, 
        {
            "source": "### Clean and structure the json date into a pandas dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "venues = results['response']['groups'][0]['items']\n\nnearby_venues = json_normalize(venues)\n\n# filtering the columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues = nearby_venues.loc[:, filtered_columns]\n\n# filter the category\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean the columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues"
        }, 
        {
            "source": "### The number of venues returned by Foursquare", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        }, 
        {
            "source": "### Apply the function to all neighbourhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n        \n        # Create the API request URL\n        url3 = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID,\n            CLIENT_SECRET,\n            VERSION,\n            lat,\n            lng,\n            radius,\n            LIMIT)\n        \n        # make the Get request\n        results = requests.get(url3).json()[\"response\"]['groups'][0]['items']\n        \n        # return only the relevant responses for each venue\n        venues_list.append([(\n            name,\n            lat,\n            lng,\n            v['venue']['name'],\n            v['venue']['location']['lat'],\n            v['venue']['location']['lng'],\n            v['venue']['categories'][0]['name']) for v in results])\n        \n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighbourhood',\n                            'Neighbourhood Latitude',\n                            'Neighbourhood Longitude',\n                            'Venue',\n                            'Venue Latitude',\n                            'Venue Longitude',\n                            'Venue Category']\n    return(nearby_venues)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_venues = getNearbyVenues(names=toronto_data['Neighbourhood'],\n                                latitudes=toronto_data['Latitude'],\n                                longitudes=toronto_data['Longitude']\n                                )"
        }, 
        {
            "source": "### check the size of the new Dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "print(toronto_venues.shape)\ntoronto_venues.head(5)"
        }, 
        {
            "source": "### The number of venues for each neighbourhood", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_venues.groupby('Neighbourhood').count()"
        }, 
        {
            "source": "### Unique categories from all of the venues", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "print('There are {} unique categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        }, 
        {
            "source": "### Analyze each of the Neighbourhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighbourhood column back to dataframe\ntoronto_onehot['Neighbourhood'] = toronto_venues['Neighbourhood'] \n\n# move neighbourhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot"
        }, 
        {
            "source": "### What is the new dataframe size?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_onehot.shape"
        }, 
        {
            "source": "Group rows by neighbourhood and the mean of the category frequency", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_grouped = toronto_onehot.groupby('Neighbourhood').mean().reset_index()\ntoronto_grouped"
        }, 
        {
            "source": "### What is the new size?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_grouped.shape"
        }, 
        {
            "source": "### Neighbourhood with top 5 most common values", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "num_top_venues = 5\n\nfor hood in toronto_grouped['Neighbourhood']:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighbourhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        }, 
        {
            "source": "### Add data to a pandas dataframe\n\n#### (Function to sort the venues in descending order)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        }, 
        {
            "source": "#### (Create dataframe and display top 10 venues per neighbourhood)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighbourhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighbourhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighbourhoods_venues_sorted['Neighbourhood'] = toronto_grouped['Neighbourhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighbourhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighbourhoods_venues_sorted.head()"
        }, 
        {
            "source": "### Cluster the Neighbourhoods\n\n#### Run k-means to group the neighbourhoods into 5 different clusters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighbourhood', 1)\ntoronto_grouped_clustering.dropna()\n\n# run k-means clustering\nk_means = KMeans(init=\"k-means++\", n_clusters=kclusters, n_init=50)\nk_means.fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nk_means.labels_.astype(int)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "neighbourhoods_venues_sorted"
        }, 
        {
            "source": "#### (Create a new dataframe that includes the clusters as well as the top 10 venues)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# add clustering labels\nneighbourhoods_venues_sorted.insert(0, 'Cluster Labels', k_means.labels_)\n\ntoronto_merged = toronto_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighbourhood\ntoronto_merged = toronto_merged.join(neighbourhoods_venues_sorted.set_index('Neighbourhood'), on='Neighbourhood')\n\ntoronto_merged.head(6) # check the last columns!"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_merged['Cluster Labels']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_merged.dropna(inplace=True)\ntoronto_merged"
        }, 
        {
            "source": "### Map the resulting clusters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lng, poi, cluster in zip(toronto_merged['Latitude'],\n                                  toronto_merged['Longitude'],\n                                  toronto_merged['Neighbourhood'],\n                                  toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' included in Cluster ' + str(cluster+1), parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color=rainbow[int(cluster-4)],\n        fill=True,\n        fill_color=rainbow[int(cluster-1)],\n        fill_opacity=1).add_to(map_clusters)\n       \nmap_clusters"
        }, 
        {
            "source": "## By grouping the results by the 1st Most Common Venue, we can classify the Neighbourhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Examine the Clusters\n\n### Cluster 1", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0,\n                   toronto_merged.columns[[1,2] + list(range(6, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_merged[toronto_merged['Cluster Labels'] == 0].groupby('1st Most Common Venue').size()"
        }, 
        {
            "source": "### Cluster 2", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1,\n                   toronto_merged.columns[[1,2] + list(range(6, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged[toronto_merged['Cluster Labels'] == 1].groupby('1st Most Common Venue').size()"
        }, 
        {
            "source": "### Cluster 3", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2,\n                   toronto_merged.columns[[1,2] + list(range(6, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged[toronto_merged['Cluster Labels'] == 2].groupby('1st Most Common Venue').size()"
        }, 
        {
            "source": "### Cluster 4", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3,\n                   toronto_merged.columns[[1,2] + list(range(6, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged[toronto_merged['Cluster Labels'] == 3].groupby('1st Most Common Venue').size()"
        }, 
        {
            "source": "### Cluster 5", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4,\n                   toronto_merged.columns[[1,2] + list(range(6, toronto_merged.shape[1]))]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "toronto_merged[toronto_merged['Cluster Labels'] == 4].groupby('1st Most Common Venue').size()"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}